#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""Streamlit + CRNNæ¨¡å‹æ•´åˆ - è‡ªå‹•é©—è­‰ç¢¼è­˜åˆ¥å·¥å…· (åƒç…§Flaskç‰ˆæœ¬åŠŸèƒ½)"""

import streamlit as st
import torch
import torch.nn as nn
import torchvision.transforms as transforms
from PIL import Image
import os
import re
import string
import time
from pathlib import Path
import warnings
from typing import List, Tuple, Dict, Optional
import sys
import subprocess

# æŠ‘åˆ¶è­¦å‘Š
warnings.filterwarnings('ignore')

# æª¢æŸ¥æ˜¯å¦åœ¨æ­£ç¢ºçš„Streamlitç’°å¢ƒä¸­é‹è¡Œ
def check_streamlit_context():
    """æª¢æŸ¥æ˜¯å¦åœ¨æ­£ç¢ºçš„Streamlitç’°å¢ƒä¸­é‹è¡Œ"""
    try:
        # æª¢æŸ¥æ˜¯å¦å­˜åœ¨streamlitçš„é‹è¡Œä¸Šä¸‹æ–‡
        import streamlit.runtime.scriptrunner.script_run_context as script_run_context
        ctx = script_run_context.get_script_run_ctx()
        return ctx is not None
    except:
        return False

# å¦‚æœä¸åœ¨Streamlitä¸Šä¸‹æ–‡ä¸­é‹è¡Œï¼Œæä¾›å‹å¥½çš„éŒ¯èª¤ä¿¡æ¯ä¸¦å˜—è©¦è‡ªå‹•å•Ÿå‹•
if not check_streamlit_context():
    print("\n" + "="*60)
    print("ğŸš¨ è«‹ä½¿ç”¨æ­£ç¢ºçš„æ–¹å¼é‹è¡Œæ­¤Streamlitæ‡‰ç”¨ï¼")
    print("="*60)
    print("\næ­£ç¢ºçš„é‹è¡Œæ–¹å¼ï¼š")
    print("1. é–‹å•Ÿå‘½ä»¤æç¤ºç¬¦æˆ–PowerShell")
    print(f"2. åˆ‡æ›åˆ°æ‡‰ç”¨ç›®éŒ„ï¼š")
    current_dir = os.path.dirname(os.path.abspath(__file__))
    print(f"   cd {current_dir}")
    print("3. é‹è¡Œä»¥ä¸‹å‘½ä»¤ï¼š")
    print("   streamlit run app.py")
    print(f"\næˆ–è€…ç›´æ¥é‹è¡Œï¼š")
    print(f"   streamlit run {os.path.abspath(__file__)}")
    print("\n" + "="*60)
    print("ğŸ’¡ æç¤ºï¼šä¸è¦ç›´æ¥ç”¨pythonåŸ·è¡Œæ­¤æ–‡ä»¶ï¼")
    print("="*60)
    
    # å˜—è©¦è‡ªå‹•å•Ÿå‹•streamlit
    try:
        current_file = os.path.abspath(__file__)
        print("ğŸš€ æ­£åœ¨å˜—è©¦è‡ªå‹•å•Ÿå‹•Streamlit...")
        subprocess.run([sys.executable, "-m", "streamlit", "run", current_file])
    except Exception as e:
        print(f"âŒ è‡ªå‹•å•Ÿå‹•å¤±æ•—ï¼š{e}")
        print("è«‹æ‰‹å‹•ä½¿ç”¨ä¸Šè¿°å‘½ä»¤é‹è¡Œã€‚")
    
    sys.exit(1)

# é é¢é…ç½®
st.set_page_config(
    page_title="ğŸ¯ AIé©—è­‰ç¢¼è­˜åˆ¥å·¥å…·",
    page_icon="ğŸ¯",
    layout="wide",
    initial_sidebar_state="expanded"
)

# æ¨¡å‹é…ç½® - åƒç…§Flaskç‰ˆæœ¬ï¼Œæ ¹æ“šé …ç›®çµæ§‹èª¿æ•´
MODEL_PATHS = [
    "best_crnn_captcha_model.pth",  # ä¸»ç›®éŒ„ä¸­çš„æ¨¡å‹æª”æ¡ˆ
    r"C:\Users\User\Desktop\Python3.8\02_emnist\trained_models\best_crnn_captcha_model.pth",
    "model.pth", 
    "crnn_model.pth"
]

CHARACTERS = string.ascii_uppercase
CAPTCHA_LENGTH_EXPECTED = 4

DEFAULT_CONFIG = {
    'IMAGE_HEIGHT': 32,
    'IMAGE_WIDTH': 128,
    'INPUT_CHANNELS': 1,
    'SEQUENCE_LENGTH': CAPTCHA_LENGTH_EXPECTED,
    'NUM_CLASSES': len(CHARACTERS),
    'HIDDEN_SIZE': 256,
    'NUM_LAYERS': 2
}

CHAR_TO_IDX = {char: idx for idx, char in enumerate(CHARACTERS)}
IDX_TO_CHAR = {idx: char for idx, char in enumerate(CHARACTERS)}

# é«˜ç´šè‡ªå®šç¾©CSSæ¨£å¼ - æ–°æ½®é…è‰²ç‰ˆ
st.markdown("""
<style>
    /* ä¸»é«”èƒŒæ™¯ - æ·±é‚ƒæ¼¸è®Š */
    .main .block-container {
        padding-top: 1rem;
        padding-bottom: 1rem;
        background: linear-gradient(135deg, #0f0f23, #1a1a2e, #16213e);
        min-height: 100vh;
    }
    
    /* æ¨™é¡Œæ¨£å¼ - éœ“è™¹é’è— */
    .main-title {
        background: linear-gradient(135deg, #00d4ff, #0099cc, #0066aa);
        padding: 2rem;
        border-radius: 20px;
        text-align: center;
        margin-bottom: 2rem;
        box-shadow: 0 10px 30px rgba(0, 212, 255, 0.3);
        color: #ffffff;
        border: 1px solid rgba(0, 212, 255, 0.5);
        backdrop-filter: blur(10px);
    }
    
    /* AIç‹€æ…‹å¡ç‰‡ - éœ“è™¹ç¶  */
    .ai-status-card {
        background: linear-gradient(135deg, #00ff87, #00cc6a, #00994f);
        color: #0f0f23;
        padding: 1rem;
        border-radius: 15px;
        text-align: center;
        font-weight: bold;
        margin: 1rem 0;
        box-shadow: 0 8px 25px rgba(0, 255, 135, 0.3);
        border: 1px solid rgba(0, 255, 135, 0.5);
    }
    
    .ai-status-error {
        background: linear-gradient(135deg, #ff3366, #cc1144, #990022);
        color: #ffffff;
        box-shadow: 0 8px 25px rgba(255, 51, 102, 0.3);
        border: 1px solid rgba(255, 51, 102, 0.5);
    }
    
    /* AIçµæœé¡¯ç¤º - éœ“è™¹ç´« */
    .ai-result {
        background: linear-gradient(135deg, #8b5cf6, #7c3aed, #6d28d9);
        padding: 1.5rem;
        border-radius: 15px;
        color: white;
        font-weight: bold;
        text-align: center;
        margin: 1rem 0;
        font-size: 1.2rem;
        box-shadow: 0 8px 25px rgba(139, 92, 246, 0.4);
        border: 1px solid rgba(139, 92, 246, 0.6);
    }
    
    /* æˆåŠŸçµæœ - éœ“è™¹æ©™ */
    .success-result {
        background: linear-gradient(135deg, #ff6b35, #e55100, #cc4400);
        padding: 1rem;
        border-radius: 15px;
        color: white;
        font-weight: bold;
        text-align: center;
        margin: 1rem 0;
        box-shadow: 0 8px 25px rgba(255, 107, 53, 0.4);
        border: 1px solid rgba(255, 107, 53, 0.6);
    }
    
    /* çµ±è¨ˆå¡ç‰‡ - éœ“è™¹é’ */
    .metric-card {
        background: linear-gradient(135deg, #06ffa5, #00d4ff, #0099cc);
        color: #0f0f23;
        padding: 1rem;
        border-radius: 15px;
        text-align: center;
        margin: 0.5rem;
        box-shadow: 0 6px 20px rgba(6, 255, 165, 0.3);
        border: 1px solid rgba(6, 255, 165, 0.5);
    }
    
    /* Streamlitå…ƒç´ å„ªåŒ– */
    .stMetric {
        background: linear-gradient(135deg, #1a1a2e, #16213e) !important;
        padding: 1rem !important;
        border-radius: 15px !important;
        border: 1px solid rgba(0, 212, 255, 0.3) !important;
        box-shadow: 0 4px 15px rgba(0, 0, 0, 0.3) !important;
    }
    
    .stMetric > div {
        color: #00d4ff !important;
    }
    
    .stMetric [data-testid="metric-value"] {
        color: #06ffa5 !important;
        font-weight: bold !important;
    }
    
    /* æŒ‰éˆ•æ¨£å¼ */
    .stButton > button {
        background: linear-gradient(135deg, #00d4ff, #0099cc) !important;
        color: #0f0f23 !important;
        border: none !important;
        border-radius: 10px !important;
        font-weight: bold !important;
        transition: all 0.3s ease !important;
        box-shadow: 0 4px 15px rgba(0, 212, 255, 0.3) !important;
    }
    
    .stButton > button:hover {
        background: linear-gradient(135deg, #06ffa5, #00ff87) !important;
        transform: translateY(-2px) !important;
        box-shadow: 0 6px 20px rgba(6, 255, 165, 0.4) !important;
    }
    
    /* ä¸»è¦æŒ‰éˆ•æ¨£å¼ */
    .stButton > button[kind="primary"] {
        background: linear-gradient(135deg, #8b5cf6, #7c3aed) !important;
        color: white !important;
        box-shadow: 0 4px 15px rgba(139, 92, 246, 0.4) !important;
    }
    
    .stButton > button[kind="primary"]:hover {
        background: linear-gradient(135deg, #ff6b35, #e55100) !important;
        box-shadow: 0 6px 20px rgba(255, 107, 53, 0.5) !important;
    }
    
    /* è¼¸å…¥æ¡†æ¨£å¼ */
    .stTextInput > div > div > input {
        background: rgba(26, 26, 46, 0.8) !important;
        border: 2px solid rgba(0, 212, 255, 0.5) !important;
        border-radius: 10px !important;
        color: #00d4ff !important;
        font-weight: bold !important;
    }
    
    .stTextInput > div > div > input:focus {
        border-color: #06ffa5 !important;
        box-shadow: 0 0 15px rgba(6, 255, 165, 0.5) !important;
    }
    
    /* é€²åº¦æ¢ */
    .stProgress > div > div > div > div {
        background: linear-gradient(90deg, #ff3366, #ff6b35, #06ffa5, #00d4ff) !important;
        border-radius: 10px !important;
    }
    
    /* å´é‚Šæ¬„æ¨£å¼ */
    .css-1d391kg {
        background: linear-gradient(180deg, #1a1a2e, #0f0f23) !important;
    }
    
    /* éš±è—Streamlité»˜èªå…ƒç´  */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    .stDeployButton {display:none;}
    header {visibility: hidden;}
    
    /* åœ–ç‰‡å®¹å™¨æ¨£å¼ */
    .image-container {
        text-align: center;
        padding: 1rem;
        background: linear-gradient(135deg, #1a1a2e, #16213e);
        border-radius: 15px;
        margin: 1rem 0;
        border: 1px solid rgba(0, 212, 255, 0.3);
        box-shadow: 0 4px 15px rgba(0, 0, 0, 0.3);
    }
    
    /* åˆ—è¡¨é …ç›®æ¨£å¼ */
    .image-item {
        background: linear-gradient(135deg, #1a1a2e, #16213e);
        padding: 0.5rem;
        margin: 0.2rem 0;
        border-radius: 10px;
        border-left: 4px solid #00d4ff;
        box-shadow: 0 2px 10px rgba(0, 0, 0, 0.3);
        transition: all 0.3s ease;
    }
    
    .image-item.modified {
        border-left-color: #06ffa5;
        background: linear-gradient(135deg, #0d2818, #1a2e1a);
        box-shadow: 0 2px 10px rgba(6, 255, 165, 0.2);
    }
    
    .image-item.current {
        border-left-color: #ff6b35;
        background: linear-gradient(135deg, #2e1a0d, #2e2a1a);
        box-shadow: 0 4px 15px rgba(255, 107, 53, 0.3);
    }
    
    /* æ–‡å­—é¡è‰²å„ªåŒ– */
    .stMarkdown {
        color: #e2e8f0 !important;
    }
    
    h1, h2, h3, h4, h5, h6 {
        color: #00d4ff !important;
    }
    
    /* é¸æ“‡æ¡†æ¨£å¼ */
    .stSelectbox > div > div {
        background: rgba(26, 26, 46, 0.8) !important;
        border: 2px solid rgba(0, 212, 255, 0.5) !important;
        border-radius: 10px !important;
    }
    
    /* æª”æ¡ˆä¸Šå‚³å™¨æ¨£å¼ */
    .stFileUploader > div {
        background: linear-gradient(135deg, #1a1a2e, #16213e) !important;
        border: 2px dashed rgba(0, 212, 255, 0.5) !important;
        border-radius: 15px !important;
    }
    
    /* è³‡è¨Šæ¡†æ¨£å¼ */
    .stInfo {
        background: linear-gradient(135deg, rgba(0, 212, 255, 0.1), rgba(6, 255, 165, 0.1)) !important;
        border-left: 4px solid #00d4ff !important;
        border-radius: 10px !important;
    }
    
    .stSuccess {
        background: linear-gradient(135deg, rgba(6, 255, 165, 0.1), rgba(0, 255, 135, 0.1)) !important;
        border-left: 4px solid #06ffa5 !important;
        border-radius: 10px !important;
    }
    
    .stError {
        background: linear-gradient(135deg, rgba(255, 51, 102, 0.1), rgba(255, 107, 53, 0.1)) !important;
        border-left: 4px solid #ff3366 !important;
        border-radius: 10px !important;
    }
    
    .stWarning {
        background: linear-gradient(135deg, rgba(255, 107, 53, 0.1), rgba(255, 185, 0, 0.1)) !important;
        border-left: 4px solid #ff6b35 !important;
        border-radius: 10px !important;
    }
    
    /* åˆ†éš”ç·šæ¨£å¼ */
    hr {
        border: none !important;
        height: 2px !important;
        background: linear-gradient(90deg, #00d4ff, #06ffa5, #8b5cf6) !important;
        margin: 2rem 0 !important;
        border-radius: 1px !important;
    }
</style>
""", unsafe_allow_html=True)

# å·¥å…·é¡ - åƒç…§Flaskç‰ˆæœ¬
class SimpleCaptchaCorrector:
    @staticmethod
    def extract_label_from_filename(filename: str) -> str:
        """å¾PNGæª”åæ“·å–ç¬¬ä¸€çµ„4å€‹å¤§å¯«è‹±æ–‡å­—æ¯"""
        name_without_ext, ext = os.path.splitext(filename)
        if ext.lower() not in ['.png', '.jpg', '.jpeg']:
            return ""
        match = re.search(r'([A-Z]{4})', name_without_ext)
        return match.group(1).upper() if match else ""

    @staticmethod
    def validate_label(label: str) -> bool:
        """é©—è­‰æ˜¯å¦ç‚º4ä½å¤§å¯«è‹±æ–‡å­—æ¯"""
        return bool(re.fullmatch(r'[A-Z]{4}', label))

    @staticmethod
    def generate_new_filename(new_label: str) -> str:
        """ä¾æ–°æ¨™ç±¤ç”¢ç”Ÿæª”å"""
        return f"{new_label}.png"

# CRNNæ¨¡å‹ - åƒç…§Flaskç‰ˆæœ¬
class CRNN(nn.Module):
    def __init__(self, img_height, img_width, num_classes, hidden_size=256, num_layers=2):
        super(CRNN, self).__init__()
        self.cnn = nn.Sequential(
            nn.Conv2d(1, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(inplace=True), nn.MaxPool2d(2, 2),
            nn.Conv2d(64, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(inplace=True), nn.MaxPool2d(2, 2),
            nn.Conv2d(128, 256, 3, padding=1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, 3, padding=1), nn.BatchNorm2d(256), nn.ReLU(inplace=True), nn.MaxPool2d((2, 1), (2, 1)),
            nn.Conv2d(256, 512, 3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),
            nn.Conv2d(512, 512, 3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True), nn.MaxPool2d((2, 1), (2, 1)),
            nn.Conv2d(512, 512, 2, padding=0), nn.BatchNorm2d(512), nn.ReLU(inplace=True)
        )
        self.rnn = nn.LSTM(512, hidden_size, num_layers, bidirectional=True, batch_first=True)
        self.classifier = nn.Linear(hidden_size * 2, num_classes)
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        conv_features = self.cnn(x)
        conv_features = conv_features.squeeze(2).permute(0, 2, 1)
        rnn_output, _ = self.rnn(conv_features)
        rnn_output = self.dropout(rnn_output)
        output = self.classifier(rnn_output)
        return output

# é æ¸¬å™¨é¡ - åƒç…§Flaskç‰ˆæœ¬
class CRNNPredictor:
    def __init__(self):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model = None
        self.transform = None
        self.config = None
        self.is_loaded = False
        self.model_info = {}

    def load_model(self, model_path: str):
        """è¼‰å…¥CRNNæ¨¡å‹"""
        try:
            if not os.path.exists(model_path):
                print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
                return False

            print(f"ğŸ”„ æ­£åœ¨è¼‰å…¥æ¨¡å‹: {model_path}")
            checkpoint = torch.load(model_path, map_location=self.device)
            
            if 'config' in checkpoint:
                self.config = checkpoint['config']
            else:
                self.config = DEFAULT_CONFIG.copy()

            for key, val in DEFAULT_CONFIG.items():
                self.config.setdefault(key, val)

            self.model = CRNN(
                img_height=self.config['IMAGE_HEIGHT'],
                img_width=self.config['IMAGE_WIDTH'],
                num_classes=self.config['NUM_CLASSES'],
                hidden_size=self.config['HIDDEN_SIZE'],
                num_layers=self.config['NUM_LAYERS']
            ).to(self.device)

            if 'model_state_dict' in checkpoint:
                sd_key = 'model_state_dict'
            elif 'state_dict' in checkpoint:
                sd_key = 'state_dict'
            else:
                print("âŒ æ‰¾ä¸åˆ° model_state_dict æˆ– state_dict")
                return False

            self.model.load_state_dict(checkpoint[sd_key])
            self.model.eval()

            self.transform = transforms.Compose([
                transforms.Grayscale(self.config['INPUT_CHANNELS']),
                transforms.Resize((self.config['IMAGE_HEIGHT'], self.config['IMAGE_WIDTH'])),
                transforms.ToTensor(),
                transforms.Normalize([0.5] * self.config['INPUT_CHANNELS'], [0.5] * self.config['INPUT_CHANNELS'])
            ])

            self.is_loaded = True
            self.model_info = {
                'epoch': checkpoint.get('epoch', 'unknown'),
                'best_val_captcha_acc': checkpoint.get('best_val_captcha_acc', 0),
                'idx_to_char': checkpoint.get('idx_to_char', IDX_TO_CHAR)
            }

            print(f"âœ… CRNNæ¨¡å‹è¼‰å…¥æˆåŠŸ (epoch={self.model_info['epoch']}, acc={self.model_info['best_val_captcha_acc']:.4f})")
            return True

        except Exception as e:
            print(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
            return False

    def predict(self, image: Image.Image) -> Tuple[str, float]:
        """å°å–®å¼µåœ–ç‰‡åšé æ¸¬"""
        if not self.is_loaded:
            return "", 0.0

        try:
            if image.mode != 'RGB':
                image = image.convert('RGB')

            input_tensor = self.transform(image).unsqueeze(0).to(self.device)
            
            with torch.no_grad():
                outputs = self.model(input_tensor)

            _, width_cnn_output, _ = outputs.shape
            seq_len = self.config['SEQUENCE_LENGTH']

            if width_cnn_output >= seq_len:
                start = (width_cnn_output - seq_len) // 2
                focused = outputs[:, start:start + seq_len, :]
            else:
                pad = seq_len - width_cnn_output
                focused = torch.cat([outputs, outputs[:, -1:, :].repeat(1, pad, 1)], dim=1)

            pred_indices = torch.argmax(focused, dim=2)[0]
            idx_to_char_map = self.model_info.get('idx_to_char', IDX_TO_CHAR)
            
            if isinstance(next(iter(idx_to_char_map.keys())), str):
                idx_to_char_map = {int(k): v for k, v in idx_to_char_map.items()}

            text = ''.join(idx_to_char_map.get(idx.item(), '?') for idx in pred_indices).upper()

            probs = torch.softmax(focused, dim=2)
            max_probs = torch.max(probs, dim=2)[0]
            confidence = float(torch.mean(max_probs).item())

            return text, confidence

        except Exception as e:
            print(f"âŒ é æ¸¬å¤±æ•—: {e}")
            return "", 0.0

def check_project_files():
    """æª¢æŸ¥é …ç›®ä¸­çš„é‡è¦æª”æ¡ˆ"""
    current_dir = Path(".")
    
    # æª¢æŸ¥æ¨¡å‹æª”æ¡ˆ
    model_files = []
    for model_path in MODEL_PATHS:
        if Path(model_path).exists():
            model_files.append(model_path)
    
    # æª¢æŸ¥åœ–ç‰‡è³‡æ–™å¤¾
    image_folders = []
    for item in current_dir.iterdir():
        if item.is_dir() and not item.name.startswith('.'):
            png_count = len(list(item.glob('*.png')))
            if png_count > 0:
                image_folders.append(f"{item.name} ({png_count} PNGæª”æ¡ˆ)")
    
    return model_files, image_folders
def init_session_state():
    """åˆå§‹åŒ–session stateè®Šé‡"""
    defaults = {
        'folder_images': [],
        'current_index': 0,
        'ai_predictions': {},
        'modified_labels': {},
        'modified_count': 0,
        'modified_files': set(),
        'ai_accurate_count': 0,
        'folder_path': "massive_real_captchas"  # æ ¹æ“šæ‚¨çš„é …ç›®çµæ§‹èª¿æ•´é è¨­è·¯å¾‘
    }
    
    for key, default_value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = default_value

# è¼‰å…¥æ¨¡å‹ï¼ˆä½¿ç”¨ç·©å­˜ï¼‰
@st.cache_resource
def load_crnn_model():
    """è¼‰å…¥ä¸¦ç·©å­˜CRNNæ¨¡å‹"""
    predictor = CRNNPredictor()
    
    model_files = ['best_crnn_captcha_model.pth', 'model.pth', 'crnn_model.pth']
    model_path = None
    
    for file in model_files:
        if os.path.exists(file):
            model_path = file
            break
    
    if model_path is None:
        return None
    
    if predictor.load_model(model_path):
        return predictor
    else:
        return None

def load_images_from_folder(folder_path: str):
    """å¾è³‡æ–™å¤¾è¼‰å…¥åœ–ç‰‡"""
    try:
        resolved_path = Path(folder_path).resolve()
        
        if not resolved_path.exists():
            st.error(f"âŒ è·¯å¾‘ä¸å­˜åœ¨: {resolved_path}")
            return False
            
        if not resolved_path.is_dir():
            st.error(f"âŒ è·¯å¾‘éè³‡æ–™å¤¾: {resolved_path}")
            return False

        image_files_list = []
        for p in resolved_path.glob('*.png'):
            if p.is_file():
                image_files_list.append({
                    'name': p.name, 
                    'path': str(p),
                    'original_label': SimpleCaptchaCorrector.extract_label_from_filename(p.name)
                })
        
        image_files_list.sort(key=lambda x: x['name'])
        
        if not image_files_list:
            st.error(f"âŒ è³‡æ–™å¤¾ä¸­æ²’æœ‰PNGæª”æ¡ˆ: {resolved_path}")
            return False

        st.session_state.folder_images = image_files_list
        st.session_state.current_index = 0
        st.session_state.ai_predictions = {}
        st.session_state.modified_labels = {}
        st.session_state.modified_count = 0
        st.session_state.modified_files = set()
        st.session_state.ai_accurate_count = 0
        
        st.success(f"âœ… æˆåŠŸè¼‰å…¥ {len(image_files_list)} å¼µPNGåœ–ç‰‡")
        return True
        
    except Exception as e:
        st.error(f"âŒ è¼‰å…¥åœ–ç‰‡æ™‚ç•°å¸¸: {e}")
        return False

def perform_batch_ai_prediction(predictor):
    """åŸ·è¡Œæ‰¹é‡AIé æ¸¬"""
    if not st.session_state.folder_images or not predictor:
        return
    
    # é¡¯ç¤ºé€²åº¦
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    total_files = len(st.session_state.folder_images)
    
    for i, img_info in enumerate(st.session_state.folder_images):
        status_text.text(f"ğŸ¤– AIè­˜åˆ¥ä¸­ ({i+1}/{total_files}): {img_info['name']}")
        
        try:
            image = Image.open(img_info['path'])
            predicted_text, confidence = predictor.predict(image)
            
            st.session_state.ai_predictions[i] = {
                'text': predicted_text,
                'confidence': confidence
            }
            
        except Exception as e:
            st.error(f"âŒ AIé æ¸¬å¤±æ•— {img_info['name']}: {e}")
            st.session_state.ai_predictions[i] = {'text': "ERROR", 'confidence': 0}
        
        progress_bar.progress((i + 1) / total_files)
    
    status_text.success("ğŸ¯ AIæ‰¹é‡è­˜åˆ¥å®Œæˆï¼")
    progress_bar.empty()

def save_current_file(new_label: str):
    """ä¿å­˜ç•¶å‰æ–‡ä»¶çš„ä¿®æ”¹"""
    if not st.session_state.folder_images:
        return False
    
    current_idx = st.session_state.current_index
    current_file = st.session_state.folder_images[current_idx]
    
    if not SimpleCaptchaCorrector.validate_label(new_label):
        st.error("âŒ æ¨™ç±¤å¿…é ˆç‚º4å€‹å¤§å¯«è‹±æ–‡å­—æ¯")
        return False
    
    try:
        old_path = Path(current_file['path'])
        new_filename = SimpleCaptchaCorrector.generate_new_filename(new_label)
        new_path = old_path.parent / new_filename
        
        # æª¢æŸ¥æ˜¯å¦éœ€è¦æ”¹å
        if old_path.resolve() == new_path.resolve():
            st.info(f"â„¹ï¸ æª”åæœªè®Šæ›´: {new_filename}")
            return True
        
        # å¦‚æœç›®æ¨™æª”æ¡ˆå­˜åœ¨ï¼Œæœƒè¢«è¦†è“‹
        if new_path.exists():
            st.warning(f"âš ï¸ ç›®æ¨™æª”æ¡ˆ {new_filename} å·²å­˜åœ¨ï¼Œå°‡è¢«è¦†è“‹")
        
        # åŸ·è¡Œæ”¹å
        old_path.replace(new_path)
        
        # æ›´æ–°è¨˜éŒ„
        original_label = current_file['original_label']
        if (st.session_state.ai_predictions.get(current_idx) and 
            st.session_state.ai_predictions[current_idx]['text'] == new_label and 
            original_label != new_label):
            st.session_state.ai_accurate_count += 1
        
        st.session_state.folder_images[current_idx] = {
            'name': new_filename,
            'path': str(new_path),
            'original_label': new_label
        }
        
        if current_idx not in st.session_state.modified_files:
            st.session_state.modified_count += 1
            st.session_state.modified_files.add(current_idx)
        
        st.success(f"âœ… æª”æ¡ˆå·²æ”¹åç‚º: {new_filename}")
        return True
        
    except Exception as e:
        st.error(f"âŒ ä¿å­˜å¤±æ•—: {e}")
        return False

def main():
    """ä¸»æ‡‰ç”¨ç¨‹åº"""
    try:
        # åˆå§‹åŒ–
        init_session_state()
        
        # ä¸»æ¨™é¡Œ
        st.markdown("""
        <div class="main-title">
            <h1>ğŸ¯ AIé©—è­‰ç¢¼è­˜åˆ¥å·¥å…· - CRNNè‡ªå‹•è­˜åˆ¥ç‰ˆ</h1>
            <p>ä½¿ç”¨CRNNæ¨¡å‹è‡ªå‹•è­˜åˆ¥4ä½å¤§å¯«è‹±æ–‡å­—æ¯é©—è­‰ç¢¼</p>
            <p style="font-size: 0.9rem; opacity: 0.9;">ç•¶å‰é …ç›®: ai_captcha-streamlit</p>
        </div>
        """, unsafe_allow_html=True)

        # è¼‰å…¥æ¨¡å‹
        with st.spinner("ğŸ”„ æ­£åœ¨è¼‰å…¥CRNNæ¨¡å‹..."):
            predictor = load_crnn_model()
        
        # æª¢æŸ¥é …ç›®æª”æ¡ˆ
        model_files, image_folders = check_project_files()
        
        # å´é‚Šæ¬„
        with st.sidebar:
            st.markdown("### âš™ï¸ æ§åˆ¶é¢æ¿")
            
            # é …ç›®æª”æ¡ˆç‹€æ…‹
            st.markdown("### ğŸ“‹ é …ç›®æª”æ¡ˆç‹€æ…‹")
            
            # æ¨¡å‹æª”æ¡ˆç‹€æ…‹
            if model_files:
                st.success(f"âœ… æ‰¾åˆ° {len(model_files)} å€‹æ¨¡å‹æª”æ¡ˆ")
                for model_file in model_files:
                    file_size = os.path.getsize(model_file) / (1024*1024)
                    st.text(f"ğŸ“¦ {model_file} ({file_size:.2f} MB)")
            else:
                st.error("âŒ æœªæ‰¾åˆ°æ¨¡å‹æª”æ¡ˆ")
            
            # åœ–ç‰‡è³‡æ–™å¤¾ç‹€æ…‹
            if image_folders:
                st.success(f"âœ… æ‰¾åˆ° {len(image_folders)} å€‹åœ–ç‰‡è³‡æ–™å¤¾")
                for folder in image_folders:
                    st.text(f"ğŸ“ {folder}")
            else:
                st.warning("âš ï¸ æœªæ‰¾åˆ°åŒ…å«PNGæª”æ¡ˆçš„è³‡æ–™å¤¾")
            
            # æ¨¡å‹ç‹€æ…‹
            if predictor is not None:
                st.markdown("""
                <div class="ai-status-card">
                    ğŸ¤– CRNNæ¨¡å‹å·²å°±ç·’<br>
                </div>
                """, unsafe_allow_html=True)
                
                st.markdown("### ğŸ“Š æ¨¡å‹è©³æƒ…")
                if predictor.model_info:
                    epoch = predictor.model_info.get('epoch', 'unknown')
                    accuracy = predictor.model_info.get('best_val_captcha_acc', 0)
                    st.info(f"ğŸ“ˆ è¨“ç·´è¼ªæ•¸: {epoch}")
                    st.info(f"ğŸ“Š é©—è­‰æº–ç¢ºç‡: {accuracy:.4f}")
                    st.info(f"ğŸ”¤ æ”¯æ´å­—ç¬¦: {CHARACTERS}")
                    st.info(f"ğŸ“ åºåˆ—é•·åº¦: {CAPTCHA_LENGTH_EXPECTED}")
            else:
                st.markdown("""
                <div class="ai-status-card ai-status-error">
                    âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—<br>
                    è«‹æª¢æŸ¥æ¨¡å‹æ–‡ä»¶
                </div>
                """, unsafe_allow_html=True)
                st.error("æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶ã€‚è«‹ç¢ºä¿ä»¥ä¸‹ä»»ä¸€æ–‡ä»¶å­˜åœ¨ï¼š")
                for path in MODEL_PATHS:
                    st.error(f"â€¢ {path}")
                st.stop()
            
            st.markdown("### ğŸ¯ åŠŸèƒ½é¸æ“‡")
            page_mode = st.radio(
                "é¸æ“‡æ“ä½œæ¨¡å¼",
                ["ğŸ“ è³‡æ–™å¤¾æ‰¹é‡è™•ç†", "ğŸ“· å–®å¼µè­˜åˆ¥", "ğŸ“Š çµ±è¨ˆåˆ†æ"],
                index=0
            )

        # ä¸»è¦å…§å®¹å€åŸŸ
        if page_mode == "ğŸ“ è³‡æ–™å¤¾æ‰¹é‡è™•ç†":
            folder_batch_processing(predictor)
        elif page_mode == "ğŸ“· å–®å¼µè­˜åˆ¥":
            single_image_recognition(predictor)
        else:
            statistics_analysis(predictor)
            
    except Exception as e:
        st.error(f"âŒ æ‡‰ç”¨ç¨‹åºç™¼ç”ŸéŒ¯èª¤: {e}")
        st.error("è«‹é‡æ–°è¼‰å…¥é é¢æˆ–è¯ç¹«æ”¯æ´")

def folder_batch_processing(predictor):
    """è³‡æ–™å¤¾æ‰¹é‡è™•ç†åŠŸèƒ½"""
    st.markdown("## ğŸ“ è³‡æ–™å¤¾æ‰¹é‡è™•ç†")
    
    # æª¢æŸ¥é …ç›®æª”æ¡ˆ
    model_files, image_folders = check_project_files()
    
    # è·¯å¾‘è¨­å®šå€åŸŸ - åŸºæ–¼å¯¦éš›å­˜åœ¨çš„è³‡æ–™å¤¾
    st.markdown("### ğŸ“‚ è³‡æ–™å¤¾è·¯å¾‘è¨­å®š")
    
    # é¡¯ç¤ºå¯ç”¨çš„åœ–ç‰‡è³‡æ–™å¤¾
    if image_folders:
        st.markdown("#### ğŸ¯ å°ˆæ¡ˆä¸­å¯ç”¨çš„åœ–ç‰‡è³‡æ–™å¤¾:")
        cols = st.columns(min(len(image_folders), 4))
        for i, folder_info in enumerate(image_folders):
            folder_name = folder_info.split(' (')[0]  # å–å¾—è³‡æ–™å¤¾åç¨±
            with cols[i % 4]:
                if st.button(f"ğŸ“ {folder_name}", help=f"é¸æ“‡: {folder_info}", key=f"proj_folder_{i}"):
                    st.session_state.folder_path = folder_name
    
    # å…¶ä»–å¸¸ç”¨è·¯å¾‘
    st.markdown("#### ğŸ”— å…¶ä»–å¸¸ç”¨è·¯å¾‘:")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        if st.button("ğŸ“ massive_real_captchas", help="è¨­å®šç‚ºé …ç›®ä¸­çš„massive_real_captchasè³‡æ–™å¤¾"):
            st.session_state.folder_path = "massive_real_captchas"
    
    with col2:
        if st.button("ğŸ–¥ï¸ æ¡Œé¢", help="è¨­å®šç‚ºæ¡Œé¢è·¯å¾‘"):
            st.session_state.folder_path = r"C:\Users\User\Desktop"
    
    with col3:
        if st.button("ğŸ“¥ ä¸‹è¼‰", help="è¨­å®šç‚ºä¸‹è¼‰è³‡æ–™å¤¾"):
            st.session_state.folder_path = r"C:\Users\User\Downloads"
    
    with col4:
        if st.button("ğŸ§ª æ¸¬è©¦æ•¸æ“š", help="è¨­å®šç‚ºæ¸¬è©¦æ•¸æ“šè·¯å¾‘"):
            st.session_state.folder_path = r"C:\Users\User\Desktop\Python3.8\02_emnist\debug_captchas_augmented_all_split\test"
    
    # è·¯å¾‘è¼¸å…¥
    folder_path = st.text_input(
        "ğŸ“ è³‡æ–™å¤¾è·¯å¾‘",
        value=st.session_state.folder_path,
        help="è«‹è¼¸å…¥åŒ…å«PNGåœ–ç‰‡çš„è³‡æ–™å¤¾çµ•å°è·¯å¾‘"
    )
    st.session_state.folder_path = folder_path
    
    # è¼‰å…¥æŒ‰éˆ•
    col_load, col_predict = st.columns(2)
    
    with col_load:
        if st.button("ğŸš€ è¼‰å…¥åœ–ç‰‡", type="primary"):
            if folder_path.strip():
                if load_images_from_folder(folder_path.strip()):
                    st.rerun()
            else:
                st.error("âŒ è«‹è¼¸å…¥è³‡æ–™å¤¾è·¯å¾‘")
    
    with col_predict:
        if st.button("ğŸ¤– é–‹å§‹AIæ‰¹é‡è­˜åˆ¥", type="secondary", disabled=not st.session_state.folder_images):
            if st.session_state.folder_images:
                perform_batch_ai_prediction(predictor)
                st.rerun()

    # æç¤ºä¿¡æ¯
    st.info("ğŸ’¡ **AIåŠŸèƒ½**: è‡ªå‹•ä½¿ç”¨CRNNæ¨¡å‹è­˜åˆ¥4ä½å¤§å¯«è‹±æ–‡å­—æ¯ (A-Z)")
    st.info("ğŸ’¡ **ä¿å­˜è¦å‰‡**: æ–°æª”åå°‡æ˜¯ä¿®æ­£å¾Œçš„4ä½å¤§å¯«è‹±æ–‡å­—æ¯ + \".png\"")
    st.warning("âš ï¸ **æ³¨æ„**: è‹¥ç›®æ¨™æª”åå·²å­˜åœ¨ï¼Œå‰‡æœƒç›´æ¥è¦†å¯«")
    
    # å¦‚æœæœ‰è¼‰å…¥çš„åœ–ç‰‡ï¼Œé¡¯ç¤ºè™•ç†ç•Œé¢
    if st.session_state.folder_images:
        display_image_processing_interface(predictor)

def display_image_processing_interface(predictor):
    """é¡¯ç¤ºåœ–ç‰‡è™•ç†ç•Œé¢"""
    st.markdown("---")
    st.markdown("## ğŸ–¼ï¸ åœ–ç‰‡è™•ç†ç•Œé¢")
    
    # çµ±è¨ˆä¿¡æ¯
    col_stats1, col_stats2, col_stats3, col_stats4 = st.columns(4)
    
    with col_stats1:
        st.metric("ğŸ“‹ ç¸½æª”æ¡ˆæ•¸", len(st.session_state.folder_images))
    
    with col_stats2:
        st.metric("âœ… å·²ä¿®æ­£", st.session_state.modified_count)
    
    with col_stats3:
        ai_acc = (st.session_state.ai_accurate_count / max(st.session_state.modified_count, 1)) * 100
        st.metric("ğŸ¤– AIæº–ç¢ºç‡", f"{ai_acc:.0f}%")
    
    with col_stats4:
        progress = (st.session_state.modified_count / len(st.session_state.folder_images)) * 100
        st.metric("ğŸ“ˆ å®Œæˆé€²åº¦", f"{progress:.0f}%")
    
    # ä¸»è¦è™•ç†å€åŸŸ
    col_list, col_main = st.columns([1, 2])
    
    with col_list:
        st.markdown("#### ğŸ“‹ åœ–ç‰‡åˆ—è¡¨")
        
        # åœ–ç‰‡åˆ—è¡¨
        list_container = st.container()
        with list_container:
            for i, img_info in enumerate(st.session_state.folder_images):
                # æ§‹å»ºé¡¯ç¤ºæ–‡æœ¬
                display_text = f"{i+1}. {img_info['name'][:20]}..."
                
                # æ·»åŠ AIé æ¸¬çµæœ
                if i in st.session_state.ai_predictions:
                    ai_pred = st.session_state.ai_predictions[i]
                    display_text += f" | AI: {ai_pred['text']}"
                
                # æ¨£å¼é¡åˆ¥
                style_class = "image-item"
                if i in st.session_state.modified_files:
                    style_class += " modified"
                if i == st.session_state.current_index:
                    style_class += " current"
                
                # é¡¯ç¤ºé …ç›®
                if st.button(
                    display_text,
                    key=f"img_btn_{i}",
                    help=f"é»æ“ŠæŸ¥çœ‹: {img_info['name']}",
                    use_container_width=True
                ):
                    st.session_state.current_index = i
                    st.rerun()
                
                # é¡¯ç¤ºæ¨£å¼æ¨™è¨˜
                if i == st.session_state.current_index:
                    st.markdown("ğŸ‘† **ç•¶å‰é¸ä¸­**")
                elif i in st.session_state.modified_files:
                    st.markdown("âœ… å·²ä¿®æ­£")
    
    with col_main:
        st.markdown("#### ğŸ–¼ï¸ ç•¶å‰åœ–ç‰‡è™•ç†")
        
        if st.session_state.current_index < len(st.session_state.folder_images):
            current_img = st.session_state.folder_images[st.session_state.current_index]
            
            # åœ–ç‰‡é¡¯ç¤º
            col_img, col_control = st.columns([2, 1])
            
            with col_img:
                try:
                    image = Image.open(current_img['path'])
                    st.image(
                        image,
                        caption=f"æª”æ¡ˆ: {current_img['name']}",
                        use_column_width=True
                    )
                except Exception as e:
                    st.error(f"âŒ ç„¡æ³•è¼‰å…¥åœ–ç‰‡: {e}")
            
            with col_control:
                st.markdown("##### ğŸ“„ æª”æ¡ˆä¿¡æ¯")
                st.text(f"æª”å: {current_img['name']}")
                st.text(f"åŸå§‹æ¨™ç±¤: {current_img['original_label'] or 'ç„¡æ³•æå–'}")
                
                # AIè­˜åˆ¥çµæœ
                current_idx = st.session_state.current_index
                if current_idx in st.session_state.ai_predictions:
                    ai_pred = st.session_state.ai_predictions[current_idx]
                    
                    st.markdown("##### ğŸ¤– AIè­˜åˆ¥çµæœ")
                    st.markdown(f"""
                    <div class="ai-result">
                        {ai_pred['text']}<br>
                        ç½®ä¿¡åº¦: {ai_pred['confidence']:.2%}
                    </div>
                    """, unsafe_allow_html=True)
                    
                    st.progress(ai_pred['confidence'])
                    
                    # ä½¿ç”¨AIçµæœæŒ‰éˆ•
                    if st.button("ğŸ¯ ä½¿ç”¨AIè­˜åˆ¥çµæœ", use_container_width=True):
                        if SimpleCaptchaCorrector.validate_label(ai_pred['text']):
                            st.session_state.temp_label = ai_pred['text']
                            st.success(f"âœ… å·²å¡«å…¥AIçµæœ: {ai_pred['text']}")
                        else:
                            st.warning("âš ï¸ AIé æ¸¬çµæœæ ¼å¼ç„¡æ•ˆ")
                
                # æ¨™ç±¤ä¿®æ­£
                st.markdown("##### âœï¸ æ¨™ç±¤ä¿®æ­£")
                
                # é è¨­å€¼é‚è¼¯
                default_value = ""
                if current_idx in st.session_state.ai_predictions:
                    ai_pred = st.session_state.ai_predictions[current_idx]
                    if (ai_pred['confidence'] > 0.7 and 
                        SimpleCaptchaCorrector.validate_label(ai_pred['text'])):
                        default_value = ai_pred['text']
                
                if not default_value and current_img['original_label']:
                    default_value = current_img['original_label']
                
                # ä½¿ç”¨è‡¨æ™‚è®Šé‡ä¾†è™•ç†è¼¸å…¥
                if 'temp_label' not in st.session_state:
                    st.session_state.temp_label = default_value
                
                new_label = st.text_input(
                    "è¼¸å…¥4å€‹å¤§å¯«å­—æ¯",
                    value=st.session_state.temp_label,
                    max_chars=4,
                    key=f"label_input_{current_idx}",
                    help="åªèƒ½è¼¸å…¥A-Zçš„å¤§å¯«å­—æ¯"
                ).upper()
                
                # æ›´æ–°è‡¨æ™‚è®Šé‡
                st.session_state.temp_label = new_label
                
                # é©—è­‰è¼¸å…¥
                is_valid = SimpleCaptchaCorrector.validate_label(new_label)
                
                if new_label:
                    if is_valid:
                        st.success(f"âœ… æ ¼å¼æ­£ç¢º: {new_label}")
                    else:
                        st.error("âŒ è«‹è¼¸å…¥4å€‹å¤§å¯«è‹±æ–‡å­—æ¯")
                
                # ä¿å­˜æŒ‰éˆ•
                if st.button(
                    "ğŸ’¾ ä¿å­˜ä¿®æ”¹",
                    disabled=not is_valid,
                    use_container_width=True,
                    type="primary"
                ):
                    if save_current_file(new_label):
                        # ä¿å­˜æˆåŠŸå¾Œè‡ªå‹•è·³åˆ°ä¸‹ä¸€å¼µ
                        if current_idx < len(st.session_state.folder_images) - 1:
                            st.session_state.current_index += 1
                            # é‡ç½®è‡¨æ™‚æ¨™ç±¤
                            next_img = st.session_state.folder_images[st.session_state.current_index]
                            next_default = ""
                            if st.session_state.current_index in st.session_state.ai_predictions:
                                next_ai = st.session_state.ai_predictions[st.session_state.current_index]
                                if (next_ai['confidence'] > 0.7 and 
                                    SimpleCaptchaCorrector.validate_label(next_ai['text'])):
                                    next_default = next_ai['text']
                            if not next_default and next_img['original_label']:
                                next_default = next_img['original_label']
                            st.session_state.temp_label = next_default
                        else:
                            st.balloons()
                            st.success("ğŸ‰ å…¨éƒ¨è™•ç†å®Œæˆï¼")
                        st.rerun()
                
                # å°èˆªæŒ‰éˆ•
                st.markdown("##### ğŸ§­ å°èˆª")
                nav_col1, nav_col2 = st.columns(2)
                
                with nav_col1:
                    if st.button(
                        "â¬…ï¸ ä¸Šä¸€å¼µ",
                        disabled=current_idx == 0,
                        use_container_width=True
                    ):
                        st.session_state.current_index -= 1
                        # æ›´æ–°è‡¨æ™‚æ¨™ç±¤
                        prev_img = st.session_state.folder_images[st.session_state.current_index]
                        prev_default = ""
                        if st.session_state.current_index in st.session_state.ai_predictions:
                            prev_ai = st.session_state.ai_predictions[st.session_state.current_index]
                            if (prev_ai['confidence'] > 0.7 and 
                                SimpleCaptchaCorrector.validate_label(prev_ai['text'])):
                                prev_default = prev_ai['text']
                        if not prev_default and prev_img['original_label']:
                            prev_default = prev_img['original_label']
                        st.session_state.temp_label = prev_default
                        st.rerun()
                
                with nav_col2:
                    if st.button(
                        "ä¸‹ä¸€å¼µ â¡ï¸",
                        disabled=current_idx >= len(st.session_state.folder_images) - 1,
                        use_container_width=True
                    ):
                        st.session_state.current_index += 1
                        # æ›´æ–°è‡¨æ™‚æ¨™ç±¤
                        next_img = st.session_state.folder_images[st.session_state.current_index]
                        next_default = ""
                        if st.session_state.current_index in st.session_state.ai_predictions:
                            next_ai = st.session_state.ai_predictions[st.session_state.current_index]
                            if (next_ai['confidence'] > 0.7 and 
                                SimpleCaptchaCorrector.validate_label(next_ai['text'])):
                                next_default = next_ai['text']
                        if not next_default and next_img['original_label']:
                            next_default = next_img['original_label']
                        st.session_state.temp_label = next_default
                        st.rerun()
                
                # é€²åº¦æŒ‡ç¤ºå™¨
                st.markdown(f"**ğŸ“ é€²åº¦**: {current_idx + 1} / {len(st.session_state.folder_images)}")
                progress_pct = (current_idx + 1) / len(st.session_state.folder_images)
                st.progress(progress_pct)

def single_image_recognition(predictor):
    """å–®å¼µåœ–ç‰‡è­˜åˆ¥"""
    st.markdown("## ğŸ“· å–®å¼µåœ–ç‰‡è­˜åˆ¥")
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.markdown("#### ğŸ–¼ï¸ ä¸Šå‚³åœ–ç‰‡")
        
        uploaded_file = st.file_uploader(
            "é¸æ“‡é©—è­‰ç¢¼åœ–ç‰‡",
            type=['png', 'jpg', 'jpeg'],
            help="æ”¯æ´PNGã€JPGã€JPEGæ ¼å¼"
        )
        
        if uploaded_file is not None:
            image = Image.open(uploaded_file)
            st.image(image, caption="ä¸Šå‚³çš„é©—è­‰ç¢¼", use_column_width=True)
            
            original_label = SimpleCaptchaCorrector.extract_label_from_filename(uploaded_file.name)
            if original_label:
                st.info(f"ğŸ“ æª”åä¸­çš„æ¨™ç±¤: **{original_label}**")
    
    with col2:
        st.markdown("#### ğŸ¯ è­˜åˆ¥çµæœ")
        
        if uploaded_file is not None:
            if st.button("ğŸš€ é–‹å§‹AIè­˜åˆ¥", type="primary", use_container_width=True):
                with st.spinner("ğŸ¤– AIæ­£åœ¨è­˜åˆ¥ä¸­..."):
                    predicted_text, confidence = predictor.predict(image)
                
                if predicted_text:
                    st.markdown(f"""
                    <div class="ai-result">
                        ğŸ¤– AIè­˜åˆ¥çµæœ: <strong>{predicted_text}</strong><br>
                        ğŸ“Š ç½®ä¿¡åº¦: {confidence:.2%}
                    </div>
                    """, unsafe_allow_html=True)
                    
                    st.progress(confidence)
                    
                    # ç½®ä¿¡åº¦è©•ä¼°
                    if confidence > 0.9:
                        st.success("ğŸŸ¢ é«˜ç½®ä¿¡åº¦ - çµæœå¯ä¿¡")
                    elif confidence > 0.7:
                        st.warning("ğŸŸ¡ ä¸­ç­‰ç½®ä¿¡åº¦ - å»ºè­°æª¢æŸ¥")
                    else:
                        st.warning("ğŸŸ  ä½ç½®ä¿¡åº¦ - éœ€è¦é©—è­‰")
                    
                    # çµæœä¿®æ­£
                    st.markdown("#### âœï¸ çµæœä¿®æ­£")
                    corrected_text = st.text_input(
                        "ä¿®æ­£çµæœ:",
                        value=predicted_text,
                        max_chars=4,
                        help="å¯ä»¥ä¿®æ­£AIè­˜åˆ¥çµæœ"
                    ).upper()
                    
                    is_valid = SimpleCaptchaCorrector.validate_label(corrected_text)
                    
                    if corrected_text and is_valid:
                        st.success(f"âœ… æ ¼å¼æ­£ç¢º: {corrected_text}")
                        
                        if st.button("ğŸ’¾ ç¢ºèªçµæœ", use_container_width=True):
                            st.markdown(f"""
                            <div class="success-result">
                                âœ… å·²ç¢ºèªçµæœ: <strong>{corrected_text}</strong><br>
                                å»ºè­°æª”å: {SimpleCaptchaCorrector.generate_new_filename(corrected_text)}
                            </div>
                            """, unsafe_allow_html=True)
                            st.balloons()
                    elif corrected_text:
                        st.error("âŒ è«‹è¼¸å…¥4å€‹å¤§å¯«è‹±æ–‡å­—æ¯")
                else:
                    st.error("âŒ AIè­˜åˆ¥å¤±æ•—ï¼Œè«‹å˜—è©¦å…¶ä»–åœ–ç‰‡")

def statistics_analysis(predictor):
    """çµ±è¨ˆåˆ†æ"""
    st.markdown("## ğŸ“Š çµ±è¨ˆåˆ†æ")
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.markdown("#### ğŸ”§ æŠ€è¡“è¦æ ¼")
        
        # ä½¿ç”¨è¡¨æ ¼é¡¯ç¤ºæŠ€è¡“è¦æ ¼
        specs_data = {
            "é …ç›®": [
                "æ¨¡å‹æ¶æ§‹",
                "æ”¯æ´å­—ç¬¦",
                "å­—ç¬¦æ•¸é‡", 
                "åºåˆ—é•·åº¦",
                "è¨ˆç®—è¨­å‚™",
                "è¼¸å…¥å°ºå¯¸",
                "éš±è—å±¤å¤§å°",
                "LSTMå±¤æ•¸"
            ],
            "è¦æ ¼": [
                "CRNN (CNN + LSTM)",
                CHARACTERS,
                len(CHARACTERS),
                CAPTCHA_LENGTH_EXPECTED,
                "CPU" if not torch.cuda.is_available() else "CUDA",
                f"{DEFAULT_CONFIG['IMAGE_HEIGHT']}Ã—{DEFAULT_CONFIG['IMAGE_WIDTH']}",
                DEFAULT_CONFIG['HIDDEN_SIZE'],
                DEFAULT_CONFIG['NUM_LAYERS']
            ]
        }
        
        import pandas as pd
        specs_df = pd.DataFrame(specs_data)
        st.dataframe(specs_df, use_container_width=True, hide_index=True)
    
    with col2:
        st.markdown("#### ğŸ“ˆ æ€§èƒ½æŒ‡æ¨™")
        
        if predictor and predictor.model_info:
            # ä½¿ç”¨æŒ‡æ¨™å¡ç‰‡é¡¯ç¤º
            st.metric(
                "è¨“ç·´è¼ªæ•¸",
                predictor.model_info.get('epoch', 'unknown')
            )
            
            accuracy = predictor.model_info.get('best_val_captcha_acc', 0)
            st.metric(
                "é©—è­‰æº–ç¢ºç‡",
                f"{accuracy:.4f}",
                f"{accuracy*100:.2f}%"
            )
            
            st.metric(
                "æ¨ç†é€Ÿåº¦",
                "~100ms/åœ–ç‰‡",
                help="å¹³å‡å–®å¼µåœ–ç‰‡è™•ç†æ™‚é–“"
            )
            
            st.metric(
                "æ”¯æ´æ ¼å¼",
                "PNG, JPG, JPEG"
            )
        else:
            st.warning("âš ï¸ æ¨¡å‹æœªæ­£ç¢ºè¼‰å…¥ï¼Œç„¡æ³•é¡¯ç¤ºæ€§èƒ½æŒ‡æ¨™")
    
    # ç•¶å‰è™•ç†çµ±è¨ˆ
    if st.session_state.folder_images:
        st.markdown("---")
        st.markdown("#### ğŸ“‹ ç•¶å‰æ‰¹æ¬¡çµ±è¨ˆ")
        
        col_stat1, col_stat2, col_stat3, col_stat4 = st.columns(4)
        
        with col_stat1:
            st.metric(
                "ğŸ“‹ ç¸½æª”æ¡ˆæ•¸",
                len(st.session_state.folder_images)
            )
        
        with col_stat2:
            st.metric(
                "âœ… å·²ä¿®æ­£æª”æ¡ˆ",
                st.session_state.modified_count,
                f"{(st.session_state.modified_count/len(st.session_state.folder_images)*100):.1f}%"
            )
        
        with col_stat3:
            ai_accuracy = 0
            if st.session_state.modified_count > 0:
                ai_accuracy = (st.session_state.ai_accurate_count / st.session_state.modified_count) * 100
            st.metric(
                "ğŸ¤– AIæº–ç¢ºç‡",
                f"{ai_accuracy:.1f}%",
                help="AIé æ¸¬èˆ‡æœ€çµ‚æ¨™ç±¤çš„åŒ¹é…ç‡"
            )
        
        with col_stat4:
            remaining = len(st.session_state.folder_images) - st.session_state.modified_count
            st.metric(
                "â³ å‰©é¤˜è™•ç†",
                remaining,
                f"{remaining} å¼µåœ–ç‰‡"
            )
        
        # AIé æ¸¬ä¿¡å¿ƒåº¦åˆ†å¸ƒ
        if st.session_state.ai_predictions:
            st.markdown("#### ğŸ“Š AIé æ¸¬ä¿¡å¿ƒåº¦åˆ†å¸ƒ")
            
            confidences = [pred['confidence'] for pred in st.session_state.ai_predictions.values()]
            
            # çµ±è¨ˆä¸åŒä¿¡å¿ƒåº¦å€é–“
            high_conf = sum(1 for c in confidences if c > 0.9)
            med_conf = sum(1 for c in confidences if 0.7 <= c <= 0.9)
            low_conf = sum(1 for c in confidences if c < 0.7)
            
            conf_col1, conf_col2, conf_col3 = st.columns(3)
            
            with conf_col1:
                st.metric(
                    "ğŸŸ¢ é«˜ä¿¡å¿ƒåº¦ (>90%)",
                    high_conf,
                    f"{(high_conf/len(confidences)*100):.1f}%"
                )
            
            with conf_col2:
                st.metric(
                    "ğŸŸ¡ ä¸­ä¿¡å¿ƒåº¦ (70-90%)",
                    med_conf,
                    f"{(med_conf/len(confidences)*100):.1f}%"
                )
            
            with conf_col3:
                st.metric(
                    "ğŸŸ  ä½ä¿¡å¿ƒåº¦ (<70%)",
                    low_conf,
                    f"{(low_conf/len(confidences)*100):.1f}%"
                )
            
            # é¡¯ç¤ºå¹³å‡ä¿¡å¿ƒåº¦
            avg_confidence = sum(confidences) / len(confidences)
            st.metric(
                "ğŸ“Š å¹³å‡ä¿¡å¿ƒåº¦",
                f"{avg_confidence:.3f}",
                f"{avg_confidence*100:.1f}%"
            )

if __name__ == "__main__":
    main()