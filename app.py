#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""Streamlit + CRNNæ¨¡å‹æ•´åˆ - è‡ªå‹•é©—è­‰ç¢¼è­˜åˆ¥å·¥å…·"""

import streamlit as st
import torch
import torch.nn as nn
import torchvision.transforms as transforms
from PIL import Image
import os
import re
import string
import io
import zipfile
import requests
from pathlib import Path
import pandas as pd
import time
from typing import List, Tuple, Dict, Optional

# é é¢é…ç½®
st.set_page_config(
    page_title="ğŸ¯ AIé©—è­‰ç¢¼è­˜åˆ¥å·¥å…·",
    page_icon="ğŸ¯",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šç¾©CSSæ¨£å¼
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(135deg, #1a1a2e, #16213e);
        padding: 2rem;
        border-radius: 10px;
        margin-bottom: 2rem;
        text-align: center;
    }
    .metric-card {
        background: linear-gradient(135deg, #2c3e50, #34495e);
        padding: 1rem;
        border-radius: 8px;
        margin: 0.5rem 0;
    }
    .ai-result {
        background: linear-gradient(135deg, #8e44ad, #9b59b6);
        padding: 1rem;
        border-radius: 8px;
        color: white;
        font-weight: bold;
        text-align: center;
        margin: 1rem 0;
    }
    .success-result {
        background: linear-gradient(135deg, #27ae60, #229954);
        padding: 1rem;
        border-radius: 8px;
        color: white;
        font-weight: bold;
        text-align: center;
        margin: 1rem 0;
    }
    .stProgress > div > div > div > div {
        background: linear-gradient(90deg, #e74c3c, #f39c12, #27ae60);
    }
</style>
""", unsafe_allow_html=True)

# æ¨¡å‹é…ç½®
CHARACTERS = string.ascii_uppercase
CAPTCHA_LENGTH_EXPECTED = 4

DEFAULT_CONFIG = {
    'IMAGE_HEIGHT': 32,
    'IMAGE_WIDTH': 128,
    'INPUT_CHANNELS': 1,
    'SEQUENCE_LENGTH': CAPTCHA_LENGTH_EXPECTED,
    'NUM_CLASSES': len(CHARACTERS),
    'HIDDEN_SIZE': 256,
    'NUM_LAYERS': 2
}

CHAR_TO_IDX = {char: idx for idx, char in enumerate(CHARACTERS)}
IDX_TO_CHAR = {idx: char for idx, char in enumerate(CHARACTERS)}

# å·¥å…·é¡
class SimpleCaptchaCorrector:
    @staticmethod
    def extract_label_from_filename(filename: str) -> str:
        """å¾PNGæª”åæ“·å–ç¬¬ä¸€çµ„4å€‹å¤§å¯«è‹±æ–‡å­—æ¯"""
        name_without_ext, ext = os.path.splitext(filename)
        if ext.lower() not in ['.png', '.jpg', '.jpeg']:
            return ""
        match = re.search(r'([A-Z]{4})', name_without_ext)
        return match.group(1).upper() if match else ""

    @staticmethod
    def validate_label(label: str) -> bool:
        """é©—è­‰æ˜¯å¦ç‚º4ä½å¤§å¯«è‹±æ–‡å­—æ¯"""
        return bool(re.fullmatch(r'[A-Z]{4}', label))

# CRNNæ¨¡å‹å®šç¾©
class CRNN(nn.Module):
    """CRNNæ¨¡å‹çµæ§‹ï¼Œèˆ‡Flaskç‰ˆæœ¬å®Œå…¨ä¸€è‡´"""
    def __init__(self, img_height, img_width, num_classes, hidden_size=256, num_layers=2):
        super(CRNN, self).__init__()
        self.cnn = nn.Sequential(
            nn.Conv2d(1, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(inplace=True), nn.MaxPool2d(2, 2),
            nn.Conv2d(64, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(inplace=True), nn.MaxPool2d(2, 2),
            nn.Conv2d(128, 256, 3, padding=1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, 3, padding=1), nn.BatchNorm2d(256), nn.ReLU(inplace=True), nn.MaxPool2d((2, 1), (2, 1)),
            nn.Conv2d(256, 512, 3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),
            nn.Conv2d(512, 512, 3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True), nn.MaxPool2d((2, 1), (2, 1)),
            nn.Conv2d(512, 512, 2, padding=0), nn.BatchNorm2d(512), nn.ReLU(inplace=True)
        )
        self.rnn = nn.LSTM(512, hidden_size, num_layers, bidirectional=True, batch_first=True)
        self.classifier = nn.Linear(hidden_size * 2, num_classes)
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        conv_features = self.cnn(x)
        conv_features = conv_features.squeeze(2).permute(0, 2, 1)
        rnn_output, _ = self.rnn(conv_features)
        rnn_output = self.dropout(rnn_output)
        output = self.classifier(rnn_output)
        return output

# æ¨¡å‹è¼‰å…¥å’Œé æ¸¬é¡
class CRNNPredictor:
    def __init__(self):
        self.device = torch.device('cpu')  # Streamlit Cloudä½¿ç”¨CPU
        self.model = None
        self.transform = None
        self.config = None
        self.is_loaded = False
        self.model_info = {}

    def load_model(self, model_path: str):
        """è¼‰å…¥CRNNæ¨¡å‹"""
        try:
            if not os.path.exists(model_path):
                st.error(f"æ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨: {model_path}")
                return False

            checkpoint = torch.load(model_path, map_location=self.device)
            
            # ç²å–é…ç½®
            if 'config' in checkpoint:
                self.config = checkpoint['config']
            else:
                self.config = DEFAULT_CONFIG.copy()

            # ç¢ºä¿é…ç½®å®Œæ•´
            for key, val in DEFAULT_CONFIG.items():
                self.config.setdefault(key, val)

            # å‰µå»ºæ¨¡å‹
            self.model = CRNN(
                img_height=self.config['IMAGE_HEIGHT'],
                img_width=self.config['IMAGE_WIDTH'],
                num_classes=self.config['NUM_CLASSES'],
                hidden_size=self.config['HIDDEN_SIZE'],
                num_layers=self.config['NUM_LAYERS']
            ).to(self.device)

            # è¼‰å…¥æ¬Šé‡
            if 'model_state_dict' in checkpoint:
                sd_key = 'model_state_dict'
            elif 'state_dict' in checkpoint:
                sd_key = 'state_dict'
            else:
                st.error("æ‰¾ä¸åˆ°model_state_dictæˆ–state_dict")
                return False

            self.model.load_state_dict(checkpoint[sd_key])
            self.model.eval()

            # å‰µå»ºtransform
            self.transform = transforms.Compose([
                transforms.Grayscale(self.config['INPUT_CHANNELS']),
                transforms.Resize((self.config['IMAGE_HEIGHT'], self.config['IMAGE_WIDTH'])),
                transforms.ToTensor(),
                transforms.Normalize([0.5] * self.config['INPUT_CHANNELS'], [0.5] * self.config['INPUT_CHANNELS'])
            ])

            self.is_loaded = True
            self.model_info = {
                'epoch': checkpoint.get('epoch', 'unknown'),
                'best_val_captcha_acc': checkpoint.get('best_val_captcha_acc', 0),
                'idx_to_char': checkpoint.get('idx_to_char', IDX_TO_CHAR)
            }

            return True

        except Exception as e:
            st.error(f"æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
            return False

    def predict(self, image: Image.Image) -> Tuple[str, float]:
        """å°å–®å¼µåœ–ç‰‡åšé æ¸¬"""
        if not self.is_loaded:
            return "", 0.0

        try:
            # ç¢ºä¿åœ–ç‰‡ç‚ºRGBæ ¼å¼
            if image.mode != 'RGB':
                image = image.convert('RGB')

            input_tensor = self.transform(image).unsqueeze(0).to(self.device)
            
            with torch.no_grad():
                outputs = self.model(input_tensor)

            _, width_cnn_output, _ = outputs.shape
            seq_len = self.config['SEQUENCE_LENGTH']

            # è™•ç†è¼¸å‡ºåºåˆ—
            if width_cnn_output >= seq_len:
                start = (width_cnn_output - seq_len) // 2
                focused = outputs[:, start:start + seq_len, :]
            else:
                pad = seq_len - width_cnn_output
                focused = torch.cat([outputs, outputs[:, -1:, :].repeat(1, pad, 1)], dim=1)

            pred_indices = torch.argmax(focused, dim=2)[0]
            idx_to_char_map = self.model_info.get('idx_to_char', IDX_TO_CHAR)
            
            # è™•ç†å­—å…¸éµçš„é¡å‹
            if isinstance(next(iter(idx_to_char_map.keys())), str):
                idx_to_char_map = {int(k): v for k, v in idx_to_char_map.items()}

            text = ''.join(idx_to_char_map.get(idx.item(), '?') for idx in pred_indices).upper()

            # è¨ˆç®—ç½®ä¿¡åº¦
            probs = torch.softmax(focused, dim=2)
            max_probs = torch.max(probs, dim=2)[0]
            confidence = float(torch.mean(max_probs).item())

            return text, confidence

        except Exception as e:
            st.error(f"é æ¸¬å¤±æ•—: {e}")
            return "", 0.0

# ä½¿ç”¨Streamlitçš„ç·©å­˜è£é£¾å™¨
@st.cache_resource
def load_crnn_model():
    """è¼‰å…¥ä¸¦ç·©å­˜CRNNæ¨¡å‹"""
    predictor = CRNNPredictor()
    
    # æª¢æŸ¥æ¨¡å‹æª”æ¡ˆ
    model_files = ['best_crnn_captcha_model.pth', 'model.pth', 'crnn_model.pth']
    model_path = None
    
    for file in model_files:
        if os.path.exists(file):
            model_path = file
            break
    
    if model_path is None:
        st.error("æœªæ‰¾åˆ°æ¨¡å‹æª”æ¡ˆã€‚è«‹ç¢ºä¿æ¨¡å‹æª”æ¡ˆåœ¨å°ˆæ¡ˆæ ¹ç›®éŒ„ä¸­ã€‚")
        st.info("æ”¯æ´çš„æª”æ¡ˆå: " + ", ".join(model_files))
        return None
    
    if predictor.load_model(model_path):
        st.success(f"âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸ: {model_path}")
        return predictor
    else:
        st.error("âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—")
        return None

def main():
    # ä¸»æ¨™é¡Œ
    st.markdown("""
    <div class="main-header">
        <h1>ğŸ¯ AIé©—è­‰ç¢¼è­˜åˆ¥å·¥å…·</h1>
        <p>ä½¿ç”¨CRNNæ¨¡å‹è‡ªå‹•è­˜åˆ¥4ä½å¤§å¯«è‹±æ–‡å­—æ¯é©—è­‰ç¢¼</p>
    </div>
    """, unsafe_allow_html=True)

    # è¼‰å…¥æ¨¡å‹
    predictor = load_crnn_model()
    
    if predictor is None:
        st.stop()

    # å´é‚Šæ¬„ - æ¨¡å‹ä¿¡æ¯
    with st.sidebar:
        st.header("âš™ï¸ æ¨¡å‹ä¿¡æ¯")
        
        if predictor.model_info:
            st.success("ğŸ¤– CRNNæ¨¡å‹å·²å°±ç·’")
            st.info(f"ğŸ“Š è¨“ç·´è¼ªæ•¸: {predictor.model_info['epoch']}")
            st.info(f"ğŸ“ˆ æº–ç¢ºç‡: {predictor.model_info['best_val_captcha_acc']:.4f}")
            st.info(f"ğŸ”¤ æ”¯æ´å­—ç¬¦: {CHARACTERS}")
            st.info(f"ğŸ“ åºåˆ—é•·åº¦: {CAPTCHA_LENGTH_EXPECTED}")
        
        st.header("ğŸ“š ä½¿ç”¨èªªæ˜")
        st.markdown("""
        1. **å–®å¼µè­˜åˆ¥**: ä¸Šå‚³å–®å¼µé©—è­‰ç¢¼åœ–ç‰‡
        2. **æ‰¹é‡è™•ç†**: ä¸Šå‚³å¤šå¼µåœ–ç‰‡æ‰¹é‡è­˜åˆ¥
        3. **çµæœä¿®æ­£**: å¯æ‰‹å‹•ä¿®æ­£AIè­˜åˆ¥çµæœ
        4. **æ•¸æ“šä¸‹è¼‰**: æ”¯æ´CSVæ ¼å¼çµæœä¸‹è¼‰
        """)

    # ä¸»è¦åŠŸèƒ½æ¨™ç±¤é 
    tab1, tab2, tab3 = st.tabs(["ğŸ“· å–®å¼µè­˜åˆ¥", "ğŸ“ æ‰¹é‡è™•ç†", "ğŸ“Š çµ±è¨ˆä¿¡æ¯"])

    with tab1:
        st.header("ğŸ“· å–®å¼µåœ–ç‰‡è­˜åˆ¥")
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.subheader("ğŸ–¼ï¸ ä¸Šå‚³åœ–ç‰‡")
            uploaded_file = st.file_uploader(
                "é¸æ“‡é©—è­‰ç¢¼åœ–ç‰‡",
                type=['png', 'jpg', 'jpeg'],
                help="æ”¯æ´PNGã€JPGã€JPEGæ ¼å¼",
                key="single_upload"
            )
            
            if uploaded_file is not None:
                image = Image.open(uploaded_file)
                st.image(image, caption="ä¸Šå‚³çš„é©—è­‰ç¢¼", use_column_width=True)
                
                # å¾æª”åæå–æ¨™ç±¤
                original_label = SimpleCaptchaCorrector.extract_label_from_filename(uploaded_file.name)
                if original_label:
                    st.info(f"ğŸ“ æª”åä¸­çš„æ¨™ç±¤: **{original_label}**")
        
        with col2:
            st.subheader("ğŸ¯ è­˜åˆ¥çµæœ")
            
            if uploaded_file is not None:
                if st.button("ğŸš€ é–‹å§‹AIè­˜åˆ¥", type="primary", key="single_predict"):
                    with st.spinner("ğŸ¤– AIæ­£åœ¨è­˜åˆ¥ä¸­..."):
                        predicted_text, confidence = predictor.predict(image)
                    
                    if predicted_text:
                        # AIçµæœé¡¯ç¤º
                        st.markdown(f"""
                        <div class="ai-result">
                            ğŸ¤– AIè­˜åˆ¥çµæœ: <strong>{predicted_text}</strong><br>
                            ğŸ“Š ç½®ä¿¡åº¦: {confidence:.2%}
                        </div>
                        """, unsafe_allow_html=True)
                        
                        # ç½®ä¿¡åº¦é€²åº¦æ¢
                        st.progress(confidence)
                        
                        # çµæœä¿®æ­£å€åŸŸ
                        st.subheader("âœï¸ çµæœä¿®æ­£")
                        corrected_text = st.text_input(
                            "å¦‚éœ€ä¿®æ­£ï¼Œè«‹è¼¸å…¥æ­£ç¢ºç­”æ¡ˆ:",
                            value=predicted_text,
                            max_chars=4,
                            help="åªèƒ½è¼¸å…¥4å€‹å¤§å¯«è‹±æ–‡å­—æ¯ (A-Z)",
                            key="single_correction"
                        ).upper()
                        
                        # é©—è­‰è¼¸å…¥
                        is_valid = SimpleCaptchaCorrector.validate_label(corrected_text)
                        
                        if corrected_text:
                            if is_valid:
                                st.success(f"âœ… æ ¼å¼æ­£ç¢º: {corrected_text}")
                            else:
                                st.error("âŒ è«‹è¼¸å…¥4å€‹å¤§å¯«è‹±æ–‡å­—æ¯")
                        
                        # ç¢ºèªæŒ‰éˆ•
                        if st.button("ğŸ’¾ ç¢ºèªçµæœ", disabled=not is_valid, key="single_confirm"):
                            st.markdown(f"""
                            <div class="success-result">
                                âœ… å·²ç¢ºèªçµæœ: <strong>{corrected_text}</strong>
                            </div>
                            """, unsafe_allow_html=True)
                            
                            # æº–ç¢ºæ€§è©•ä¼°
                            if original_label:
                                is_correct = (corrected_text == original_label)
                                ai_accurate = (predicted_text == original_label)
                                
                                col_a, col_b = st.columns(2)
                                with col_a:
                                    st.metric("ğŸ¯ æœ€çµ‚æº–ç¢ºæ€§", "âœ… æ­£ç¢º" if is_correct else "âŒ éŒ¯èª¤")
                                with col_b:
                                    st.metric("ğŸ¤– AIæº–ç¢ºæ€§", "âœ… æ­£ç¢º" if ai_accurate else "âŒ éŒ¯èª¤")
                    else:
                        st.error("âŒ AIè­˜åˆ¥å¤±æ•—ï¼Œè«‹å˜—è©¦å…¶ä»–åœ–ç‰‡")

    with tab2:
        st.header("ğŸ“ æ‰¹é‡è™•ç†")
        
        uploaded_files = st.file_uploader(
            "é¸æ“‡å¤šå¼µé©—è­‰ç¢¼åœ–ç‰‡",
            type=['png', 'jpg', 'jpeg'],
            accept_multiple_files=True,
            help="ä¸€æ¬¡å¯ä¸Šå‚³å¤šå¼µåœ–ç‰‡é€²è¡Œæ‰¹é‡è­˜åˆ¥",
            key="batch_upload"
        )
        
        if uploaded_files:
            st.info(f"ğŸ“Š å·²é¸æ“‡ **{len(uploaded_files)}** å¼µåœ–ç‰‡")
            
            # é è¦½éƒ¨åˆ†åœ–ç‰‡
            if len(uploaded_files) <= 6:
                cols = st.columns(min(len(uploaded_files), 3))
                for i, file in enumerate(uploaded_files[:6]):
                    with cols[i % 3]:
                        image = Image.open(file)
                        st.image(image, caption=file.name, use_column_width=True)
            
            if st.button("ğŸš€ é–‹å§‹æ‰¹é‡è­˜åˆ¥", type="primary", key="batch_predict"):
                results = []
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                start_time = time.time()
                
                for i, file in enumerate(uploaded_files):
                    status_text.text(f"æ­£åœ¨è™•ç†: {file.name} ({i+1}/{len(uploaded_files)})")
                    
                    try:
                        image = Image.open(file)
                        predicted_text, confidence = predictor.predict(image)
                        original_label = SimpleCaptchaCorrector.extract_label_from_filename(file.name)
                        
                        # åˆ¤æ–·ç‹€æ…‹
                        if confidence > 0.9:
                            status = "ğŸŸ¢ é«˜ä¿¡å¿ƒ"
                        elif confidence > 0.7:
                            status = "ğŸŸ¡ ä¸­ç­‰ä¿¡å¿ƒ"
                        elif confidence > 0.5:
                            status = "ğŸŸ  ä½ä¿¡å¿ƒ"
                        else:
                            status = "ğŸ”´ æ¥µä½ä¿¡å¿ƒ"
                        
                        # æº–ç¢ºæ€§æª¢æŸ¥
                        accuracy = ""
                        if original_label:
                            if predicted_text == original_label:
                                accuracy = "âœ… æ­£ç¢º"
                            else:
                                accuracy = "âŒ éŒ¯èª¤"
                        
                        results.append({
                            "æª”æ¡ˆå": file.name,
                            "åŸå§‹æ¨™ç±¤": original_label or "ç„¡",
                            "AIè­˜åˆ¥çµæœ": predicted_text or "å¤±æ•—",
                            "ç½®ä¿¡åº¦": f"{confidence:.3f}",
                            "ç‹€æ…‹": status,
                            "æº–ç¢ºæ€§": accuracy
                        })
                        
                    except Exception as e:
                        results.append({
                            "æª”æ¡ˆå": file.name,
                            "åŸå§‹æ¨™ç±¤": "éŒ¯èª¤",
                            "AIè­˜åˆ¥çµæœ": "è™•ç†å¤±æ•—",
                            "ç½®ä¿¡åº¦": "0.000",
                            "ç‹€æ…‹": "ğŸ”´ å¤±æ•—",
                            "æº–ç¢ºæ€§": "âŒ éŒ¯èª¤"
                        })
                    
                    progress_bar.progress((i + 1) / len(uploaded_files))
                
                processing_time = time.time() - start_time
                status_text.success(f"âœ… æ‰¹é‡è™•ç†å®Œæˆï¼è€—æ™‚: {processing_time:.2f} ç§’")
                
                # é¡¯ç¤ºçµæœ
                st.subheader("ğŸ“Š æ‰¹é‡è­˜åˆ¥çµæœ")
                df = pd.DataFrame(results)
                st.dataframe(df, use_container_width=True)
                
                # çµ±è¨ˆä¿¡æ¯
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    total_files = len(results)
                    st.metric("ç¸½æ–‡ä»¶æ•¸", total_files)
                
                with col2:
                    high_confidence = len([r for r in results if float(r["ç½®ä¿¡åº¦"]) > 0.9])
                    st.metric("é«˜ç½®ä¿¡åº¦", f"{high_confidence}/{total_files}")
                
                with col3:
                    if any(r["æº–ç¢ºæ€§"] for r in results if r["æº–ç¢ºæ€§"]):
                        accurate_count = len([r for r in results if r["æº–ç¢ºæ€§"] == "âœ… æ­£ç¢º"])
                        total_with_labels = len([r for r in results if r["åŸå§‹æ¨™ç±¤"] != "ç„¡"])
                        accuracy_rate = (accurate_count / total_with_labels * 100) if total_with_labels > 0 else 0
                        st.metric("æº–ç¢ºç‡", f"{accuracy_rate:.1f}%")
                    else:
                        st.metric("æº–ç¢ºç‡", "ç„¡æ¨™ç±¤æ•¸æ“š")
                
                with col4:
                    avg_confidence = sum(float(r["ç½®ä¿¡åº¦"]) for r in results) / len(results)
                    st.metric("å¹³å‡ç½®ä¿¡åº¦", f"{avg_confidence:.3f}")
                
                # ä¸‹è¼‰çµæœ
                csv = df.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label="ğŸ“¥ ä¸‹è¼‰çµæœCSV",
                    data=csv,
                    file_name=f"captcha_results_{int(time.time())}.csv",
                    mime="text/csv"
                )

    with tab3:
        st.header("ğŸ“Š æ¨¡å‹çµ±è¨ˆä¿¡æ¯")
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.subheader("ğŸ”§ æŠ€è¡“è¦æ ¼")
            specs = {
                "æ¨¡å‹æ¶æ§‹": "CRNN (CNN + LSTM)",
                "æ”¯æ´å­—ç¬¦": CHARACTERS,
                "å­—ç¬¦æ•¸é‡": len(CHARACTERS),
                "åºåˆ—é•·åº¦": CAPTCHA_LENGTH_EXPECTED,
                "è¼¸å…¥å°ºå¯¸": f"{DEFAULT_CONFIG['IMAGE_HEIGHT']}Ã—{DEFAULT_CONFIG['IMAGE_WIDTH']}",
                "éš±è—å±¤å¤§å°": DEFAULT_CONFIG['HIDDEN_SIZE'],
                "LSTMå±¤æ•¸": DEFAULT_CONFIG['NUM_LAYERS'],
                "è¨ˆç®—è¨­å‚™": "CPU (Streamlit Cloud)"
            }
            
            for key, value in specs.items():
                st.info(f"**{key}**: {value}")
        
        with col2:
            st.subheader("ğŸ“ˆ æ€§èƒ½æŒ‡æ¨™")
            if predictor.model_info:
                metrics = {
                    "è¨“ç·´è¼ªæ•¸": predictor.model_info['epoch'],
                    "é©—è­‰æº–ç¢ºç‡": f"{predictor.model_info['best_val_captcha_acc']:.4f}",
                    "æ¨¡å‹å¤§å°": "~50MB (ä¼°è¨ˆ)",
                    "æ¨ç†é€Ÿåº¦": "~100ms/åœ–ç‰‡ (CPU)",
                    "æ”¯æ´æ ¼å¼": "PNG, JPG, JPEG",
                    "æœ€å¤§åœ–ç‰‡": "10MB"
                }
                
                for key, value in metrics.items():
                    st.success(f"**{key}**: {value}")
        
        st.subheader("ğŸ’¡ ä½¿ç”¨å»ºè­°")
        st.markdown("""
        - **æœ€ä½³æ•ˆæœ**: æ¸…æ™°çš„4ä½å¤§å¯«è‹±æ–‡å­—æ¯é©—è­‰ç¢¼
        - **åœ–ç‰‡è³ªé‡**: å»ºè­°è§£æåº¦ä¸ä½æ–¼64Ã—64åƒç´ 
        - **æ ¼å¼æ”¯æ´**: PNGæ ¼å¼é€šå¸¸æ•ˆæœæœ€ä½³
        - **æ‰¹é‡è™•ç†**: å»ºè­°å–®æ¬¡ä¸è¶…é50å¼µåœ–ç‰‡
        - **ç½®ä¿¡åº¦**: >0.9ç‚ºé«˜ä¿¡å¿ƒçµæœï¼Œ<0.5å»ºè­°äººå·¥æª¢æŸ¥
        """)

if __name__ == "__main__":
    main()